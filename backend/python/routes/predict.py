from fastapi import APIRouter, UploadFile, File, HTTPException, Request
import torch
import torchvision.transforms as transforms
from PIL import Image
import io
import os
from services.servoControl import set_servo_command
from torchvision import models
import torch.nn as nn
import time
from datetime import datetime

router = APIRouter()

processing_result = None  
result_ready = False  
processing_status = False  # C·ªù ƒë·ªÉ b√°o server ƒëang x·ª≠ l√Ω
status_ready = False  # C·ªù b√°o ESP32-CAM d·ª´ng g·ª≠i ·∫£nh

# Th∆∞ m·ª•c l∆∞u ·∫£nh nh·∫≠n ƒë∆∞·ª£c
UPLOAD_FOLDER = os.path.join(os.path.dirname(__file__), "..", "received_images")
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Danh s√°ch nh√£n r√°c v√† ID servo (Th·ª© t·ª± kh·ªõp v·ªõi hu·∫•n luy·ªán)
TRASH_LABELS = ['metal', 'paper', 'plastic', 'trash']
TRASH_CATEGORIES = {label: idx for idx, label in enumerate(TRASH_LABELS)}

num_classes = len(TRASH_LABELS)  # ƒê·∫£m b·∫£o ƒë√∫ng s·ªë l·ªõp

# Kh·ªüi t·∫°o m√¥ h√¨nh MobileNetV2 v·ªõi pretrained weights
def load_model():
    try:
        model = models.mobilenet_v2(pretrained=True)  # D√πng pretrained weights
        model.classifier = nn.Sequential(
            nn.Dropout(0.4),
            nn.Linear(model.last_channel, num_classes)
        )
        # ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
        BASE_DIR = os.path.dirname(os.path.abspath(__file__))
        MODEL_PATH = os.path.join(BASE_DIR, "..", "models", "model.pth")

        # Ki·ªÉm tra n·∫øu t·ªáp m√¥ h√¨nh t·ªìn t·∫°i
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y t·ªáp m√¥ h√¨nh t·∫°i: {MODEL_PATH}")
            
        model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
        model.eval()  # Chuy·ªÉn m√¥ h√¨nh sang ch·∫ø ƒë·ªô ƒë√°nh gi√°
        return model
    except Exception as e:
        print(f"L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
        raise

# T·∫£i m√¥ h√¨nh khi kh·ªüi ƒë·ªông server
try:
    model = load_model()
except Exception as e:
    print(f"Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh: {e}")
    model = None

# Ti·ªÅn x·ª≠ l√Ω ·∫£nh gi·ªëng `test.ipynb`
IMG_SIZE = 224
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomRotation(30),  # Xoay ·∫£nh ng·∫´u nhi√™n
    transforms.RandomHorizontalFlip(),  # L·∫≠t ngang ·∫£nh
    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),  # C·∫Øt ng·∫´u nhi√™n
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

@router.post('/log')
async def receive_log(request: Request):
    log_data = await request.json()
    log_message = log_data.get("log")
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] üì° Log t·ª´ ESP32-CAM: {log_message}")
    return {"message": "Log nh·∫≠n th√†nh c√¥ng!"}

@router.get('/check_status')
async def check_status():
    global status_ready
    if processing_status:
        return {"status": "processing"}, 202  
    elif status_ready:
        status_ready = False  
        return {"status": "done"}, 200  
    return {"status": "idle"}, 204   

@router.post("/predict")
async def predict_trash(file: UploadFile = File(...)):
    try:
        # Ki·ªÉm tra n·∫øu m√¥ h√¨nh ƒë√£ t·∫£i
        if model is None:
            raise HTTPException(status_code=500, detail="M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng")
            
        # Ki·ªÉm tra lo·∫°i t·ªáp tin
        if not file.filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            raise HTTPException(status_code=400, detail="Ch·ªâ ch·∫•p nh·∫≠n t·ªáp ·∫£nh .png, .jpg ho·∫∑c .jpeg")
        
        image_bytes = await file.read()
        
        # L∆∞u ·∫£nh v√†o th∆∞ m·ª•c
        timestamp = int(time.time())
        image_filename = f"{timestamp}.jpg"
        image_path = os.path.join(UPLOAD_FOLDER, image_filename)
        
        with open(image_path, "wb") as f:
            f.write(image_bytes)

        # Chuy·ªÉn ƒë·ªïi ·∫£nh ƒë·ªÉ d·ª± ƒëo√°n
        try:
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            img_tensor = transform(image).unsqueeze(0)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh: {str(e)}")

        # D·ª± ƒëo√°n lo·∫°i r√°c
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = torch.nn.functional.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probs, 1)
            trash_type = TRASH_LABELS[predicted.item()]  # ƒê·∫£m b·∫£o nh√£n ch√≠nh x√°c
            confidence_value = confidence.item()

        # L∆∞u lo·∫°i r√°c v√†o b·ªô nh·ªõ ƒë·ªÉ ESP l·∫•y l·ªánh
        set_servo_command(trash_type, TRASH_CATEGORIES[trash_type])

        return {
            "trash_type": trash_type,
            "confidence": f"{confidence_value:.2f}",
            "servo_id": TRASH_CATEGORIES[trash_type],
            "image_saved": image_filename
        }
        print(trash_type)
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi x·ª≠ l√Ω: {str(e)}")